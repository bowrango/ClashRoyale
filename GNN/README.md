
The code implementation herein is largely adapted from [1]. The goal here is to understand how attention works and experiment with different types of graph networks.

"GNNs consist of an iterative process, which propagates the node states until equilibrium; followed by a neural network, which produces an output for each node based on its state"

# References 

[1] https://github.com/gordicaleksa/pytorch-GAT/blob/main/models/definitions/GAT.py